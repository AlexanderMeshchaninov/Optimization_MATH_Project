# Оптимизационные алгоритмы проект
![](Images/optimization_math_project.png)

## Описание проекта
Данный проект посвящен исследованию и реализации двух оптимизационных алгоритмов:

- Координатного спуска
- Стохастического градиентного спуска (SGD)

## Цель проекта: 
Реализовать и сравнить эффективность двух методов оптимизации на примере линейной регрессии, а также оценить их качество с использованием метрик MSE (Mean Squared Error) и MAE (Mean Absolute Error).

## Проект состоит из следующих этапов:

1. Загрузка данных — считывание исходного набора данных и определение целевой переменной (y) и предикторов (X).
2. Нормализация и стандартизация признаков:
3. L2-нормализация (Normalizer) перед координатным спуском.
4. Z-score стандартизация (StandardScaler) перед стохастическим градиентным спуском.
5. Реализация координатного спуска — пошаговое обновление весов модели.
6. Реализация стохастического градиентного спуска (SGD) — обновление весов на основе случайных наблюдений.
7. Оценка качества моделей с использованием метрик MSE и MAE.
8. Вывод результатов и сравнение моделей.
9. Финальный вывод по результатам

## Проект оформлен согласно требованиям:

- Решение оформлено только в Jupyter Notebook.

- Решение оформлено в соответствии с ноутбуком-шаблоном.

- Каждое задание выполнено в отдельной ячейке, выделенной под задание.

- Код для каждого задания оформлен в одной-двух Jupyter-ячейках.

- В проекте использовались только: переменные, основные структуры данных (списки, кортежи), циклы, строки с библиотеки plotly, seaborn, pandas и т.д.

- При работе с проектом использовалось руководством PEP 8.

Графики содержут: 

1. название, отражающее их суть;

2. подписи осей.

Выводы представлены в виде заключений, сделан общий вывод по проекту.